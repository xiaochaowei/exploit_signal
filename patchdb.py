import numpy as np 
import datetime
import psycopg2
import scipy.io as sio
from scipy import sparse, io
root = "single_cve_singal_data/"
conn = psycopg2.connect(user = "patch", port = 5433)
cursor = conn.cursor()
machineList2isp = {}
with open('machine_id2isp.csv', 'r') as fid:
	for row in fid.read().strip().split('\n'):
		machineList2isp[int(row.split('@@')[0])] = row.split('@@')[1].split('@:')

isp2idx = {}
with open('distinct_isp.csv', 'r') as fid:
	isp2idx = {isp: idx for idx, isp in enumerate(fid.read().strip().split('\n'))}

def save_sparse_csr(filename,array):
    np.savez(filename,data = array.data ,indices=array.indices,
             indptr =array.indptr, shape=array.shape )

def load_sparse_csr(filename):
    loader = np.load(filename)
    return csr_matrix((  loader['data'], loader['indices'], loader['indptr']),
                         shape = loader['shape'])

def getSignal(input, output,  start_date, end_date):
	products = set()
	clusters = {"chrome":{}, "firefox":{}, "thunderbird":{}, 'flashplayer':{} }
#	pre_products = ['firefox', 'chrome', 'thunderbird', 'flashplayer']
#	pre_products = ['chrome']
	with open(input , "r") as f:
		cve_list = f.read().strip().split("\n")
#	with open(input, 'r') as f:
#		cluster_list =map(int, f.read().strip('\n').split('\n'))	
#	for cluster_id in cluster_list:
	for cve in cve_list:
		if cve =="":
			continue
		#if cluster_id == "":
		#	continue
		cve = [cve]
		#print cve
		cursor.execute("""SELECT * FROM cve_cluster WHERE cve @> %s """,(list(cve),)) 
	#	cursor.execute( """ SELECT * FROM cve_cluster where cluster_id = {0};""".format(cluster_id))
		rows = cursor.fetchall()
		if not rows:
			continue
		for row in rows:	
			product = row[1]
			versions = row[3]
			published = row[4]
			exploit = row[5]
			cluster_id = row[0]
			clusters[product][cluster_id] = {"product": product, "published": published, "exploited": exploit}
			versions = parse_version_list(versions)
			if not versions:
				continue
			products.add(product) 
			cursor.execute("""SELECT distinct product_line FROM file_info where product = '{0}' ; """.format(product))
			product_lines = [tuple(line[0]) for line in cursor.fetchall() if line[0] != None]
			if len(product_lines) == 0:
				continue
			version_lines = split_versions(versions, product_lines)
			if len(version_lines) == 0:
			for line in version_lines:		
				clusters[product][cluster_id][line] = ( min(version_lines[line]), max(version_lines[line]) )
			#	print clusters[cluster_id][line]
	### to each use
		cursor.execute(""" SELECT distinct machine_id FROM machine_isp; """)
		machine_ids  =[tmp[0] for tmp in  cursor.fetchall()]
		interal = (end_date - start_date).days
	#	print products
	#	return 

		signals = {}
		total = len(machine_ids)
		#products = ['firefox']
		for product in products:
			#print clusters[product]
			machine_lists = []		
	#		signal = np.zeros((total, interal))
			signal_list = []
			isp_signal = np.zeros((len(isp2idx), interal+1))
			# isp_count = np.zeros(len(isp2idx))
			for idx, machine_id in enumerate(machine_ids):
				if idx % 1000 == 0:
					print "Process {}/{}".format(idx, total)
				if not machineList2isp.has_key(machine_id):
					continue
				cursor.execute("""SELECT product_lines, product_versions, timestamp FROM machine_state WHERE machine_id = {0} and  product = '{1}' ORDER BY timestamp, updated_line ; """.format(machine_id,product))
				rows = cursor.fetchall()
				if not rows:
					continue
				# single_signal = np.zeros(interal)
				for i in range(len(rows)):
					if rows[i][2] >= end_date:
						break
					vul_clusters = set()
					for product_line, product_version in zip(rows[i][0], rows[i][1]):
						product_line = tuple(product_line)
						product_version = tuple(product_version)
						#for cluster_id, cluster in clusters[product].items():
						#	if product_line in cluster and product == cluster['product']:
								#print cluster[product_line], product_version, cluster_id, machine_id,product		
				#				print product_line 
						vul_clusters = vul_clusters.union([(cluster_id, cluster['published']) for cluster_id, cluster in clusters[product].items() if product_line in cluster and product_version >= cluster[product_line][0] and product_version <= cluster[product_line][1] ] )
					if i == len(rows) -1 and rows[i][2] < end_date:
						for j in range((end_date - rows[i][2]).days):
							if (start_date - rows[i][2]).days > j :
								continue
							count = len([published for cluster_id, published in vul_clusters if (published - rows[-1][2]).days <= j ] )
	#						signal[idx][(rows[i][2] - start_date).days + j ] = count 
							for isp in machineList2isp[machine_id]:
								isp_signal[isp2idx[isp]][(rows[i][2] - start_date).days + j] += count
								isp_signal[isp2idx[isp]][-1] += 1
							# single_signal[(rows[i][2] - start_date).days + j] = count
					elif i != len(rows) - 1 :
						for j in range((rows[i+1][2] - rows[i][2]).days):
							if  (start_date - rows[i][2]).days > j:
								continue
							if  (end_date - rows[i][2]).days <= j :
								break 
							#if len(signal) == 0:
							# method1 	
							count = len([published for cluster_id, published in vul_clusters if (published - rows[i][2]).days <= j] )
							# method2
			#				count = len([published for cluster_id, published, patched in vun_clusters if (patched and  (patched - rows[i][2]).days <= j ) or (not patched and (published - rows[i][2]).days <= j) ]) 
	#						signal[idx][(rows[i][2] - start_date).days +j] = count 
							for isp in machineList2isp[machine_id]:
								isp_signal[isp2idx[isp]][(rows[i][2] - start_date).days + j] += count
								isp_signal[isp2idx[isp]][-1] += 1
								
			#save matrix 
			fname = root + product + "/" + cve
			isp_signal_sparse = sparse.csr_matrix(isp_signal)
			save_sparse_csr(fname, isp_signal_sparse)
		#save cve matrix

def add_patch_date():
	cursor.execute("""SELECT distinct product FROM release_date; """)
	rows =  cursor.fetchall()
	products = [row[0] for row in rows]
#	return 
	products_lines = {}
	for product in products:
		cursor.execute("""SELECT distinct product_line FROM release_date WHERE product = %s """, (product,))
		rows = cursor.fetchall()
		products_lines[product] = [tuple(row[0]) for row in rows]
	cursor.execute("""SELECT * FROM cve_cluster where cluster_id = 3626; """)
	rows = cursor.fetchall()
	
	for row in rows:
		#print row
		version = row[3]
		product = row[1]
		if not products_lines.has_key(product):
			continue
		versions = parse_version_list(version)
		if not versions:
			continue
		#print "version:", versions 
		patch_date, patch_version = get_patch_date(product, products_lines[product], versions)
#		print patch_date,patch_version
		patch_version = combine_version(patch_version)
		cursor.execute(""" update cve_cluster_extend set patch_date = %s, patch_version = %s where cluster_id = {0}""".format(row[0]), (list(patch_date), list(patch_version)))
	conn.commit()

def combine_version(versions):
	tmp_versions = []
	for tmp_version in versions:
		tmp = ".".join(str(i) for i in tmp_version)
		tmp_versions.append(tmp)
	return tmp_versions 
def add_user_patch_date(product, product_lines, versions, machine_id):
	return True 	
				
def get_patch_date(product, product_lines, versions):
	patch_date = []
	patch_version = []
	version_lines = split_versions(versions, product_lines)
	for line in version_lines:
		max_version = max(version_lines[line])
		cursor.execute(""" SELECT date, version  FROM release_date WHERE product = %s AND product_line = %s AND version > %s ORDER BY version LIMIT 1; """, (product, list(line), list(max_version)))
		rows = cursor.fetchall()
		if rows:	
			patch_date.append(rows[0][0])
			patch_version.append(rows[0][1])
#		print product
#		print max_version
#		print line, patch_date
	if len(patch_date) == 0:
		max_version = max(versions)
		cursor.execute(""" SELECT date, version FROM release_date WHERE product = %s AND version > %s ORDER BY version LIMIT 1  ;""", (product, list(max_version)))
		rows = cursor.fetchall()
		if rows :
			patch_date.append(rows[0][0])
			patch_version.append(rows[0][1])
		#print patch_date
	return patch_date, patch_version
		

def split_versions(versions, product_lines):
	version_lines = {}
	for version in versions:
		product_line = [line for line in product_lines if (version +(0, ))[:len(line)] == line]
		if product_line :
			if product_line[0] in version_lines:
				version_lines[product_line[0]].append(version)
			else:
				version_lines[product_line[0]] = [version]

	return version_lines				

def parse_version_list(version_list):
	ignore_terms = ['a', 'b', 'preview_release', 'rc']
	versions = []
	for version in version_list:
		version = version.split(':', 1)
		if len(version)> 1:
			ignore = False
			for term in ignore_terms:
				if version[1].startswith(term):
					ignore = True
					break
			if ignore:
				continue
		try:
			versions.append(tuple(parse_version(version[0])))
		except Exception as e:
			continue
	return versions

def parse_version(version):
	version = list(map(int, version.split('.')))
	while not version[-1] and len(version) > 1:
		version.pop()
	return version
start_time = datetime.datetime.strptime("2013-08-19", "%Y-%m-%d").date()
end_time = datetime.datetime.strptime("2015-01-01","%Y-%m-%d").date()
getSignal("data/random_cve2", "random2_2013_all",  start_time, end_time)
